{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model as skllm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv(\"kc_house_data.csv\")\n",
    "train_sales = pd.read_csv(\"kc_house_train_data.csv\")\n",
    "test_sales = pd.read_csv(\"kc_house_test_data.csv\")\n",
    "simple_features = ['sqft_living', 'bedrooms']\n",
    "initial_weights = np.array([1.,4.,1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1, 1180,    3],\n",
       "       [   1, 2570,    3],\n",
       "       [   1,  770,    2],\n",
       "       ...,\n",
       "       [   1, 1020,    2],\n",
       "       [   1, 1600,    3],\n",
       "       [   1, 1020,    2]], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_features_matrix(dataframe, features, output):\n",
    "  dataframe['constant'] = 1\n",
    "  features = ['constant'] + features\n",
    "  #print(features)\n",
    "  features_matrix = dataframe[features].to_numpy()\n",
    "  output_array = dataframe[output].to_numpy()\n",
    "  #print(features_matrix)\n",
    "  return (features_matrix,output_array)\n",
    "\n",
    "(features_matrix, output) = get_features_matrix(sales, simple_features, 'price')\n",
    "features_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_outcome(features_matrix,weights):\n",
    "    predictions = np.dot(features_matrix, weights)\n",
    "    return (predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalize features matrix column wise so that the weights are not influenced by the value of the feature\n",
    "\n",
    "calculating the 2-norm is simply calculating the sqrt \n",
    "of the magnitude of the vectorwhich can be done by calculating the dot-product \n",
    "and then taking a square root of the dot product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norms(features_matrix):\n",
    "    norms_matrix = np.array([]) \n",
    "    normalized_features = np.array([])\n",
    "    for i in range(len(features_matrix[0])):\n",
    "        norms_matrix = np.append(norms_matrix, np.sqrt((np.dot(features_matrix[:,i],features_matrix[:,i]))))\n",
    "        #print(norms_matrix.shape)\n",
    "    normalized_features = features_matrix/norms_matrix\n",
    "    #print(normalized_features.shape)\n",
    "    #print(norms_matrix)\n",
    "    #print(normalized_features.shape)\n",
    "    return(normalized_features, norms_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.47013605e+02, 3.34257264e+05, 5.14075870e+02])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(normalized_features, norm) = norms(features_matrix)\n",
    "normalized_features\n",
    "norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimate predictions by using the predict_outcome function defined above with normalized features, and initial weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_outcome(normalized_features, initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02675867, 0.04339256, 0.01990703, ..., 0.02289873, 0.03178473,\n",
       "       0.02289873])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for soft thresholding, where we set the weights\n",
    "equal to ro[j] (which is the correlation of the \n",
    "prediction error from the model excluding jth feature, the jth feature, this correlation would be low if the model predicts well without j, but if doesn't then the model actually requires the jth feature which can be seen from the high correlation) + shifted by some value results in an prediction error using a model that does not include the jth feature. \n",
    "\n",
    "residuals of the model that does not include the jth feature \n",
    "and the jth feature this is ensured by adding weights[j]*feature_matrix[:,j] to the negative of predictions vector\n",
    "if the model predicts very well without the jth feature\n",
    "rho would be small, thus the weight on the jth feature would be smaller\n",
    "\n",
    "here the feature_matrix is the normalized feature matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the lasso coordinate descent step function assigns weights on every\n",
    "jth feature by first checking the ro[j] value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79400300.0145229, 87939470.82325175, 80966698.66623947]\n"
     ]
    }
   ],
   "source": [
    "ro = [0 for i in range((normalized_features.shape)[1])]\n",
    "for j in range((normalized_features.shape)[1]):   \n",
    "    ro[j] = (normalized_features[:,j] * (output - predictions + (initial_weights[j] * normalized_features[:,j]))).sum()\n",
    "print(ro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_coordinate_descent_step(i, feature_matrix, output, weights, l1_penalty):\n",
    "    predictions = predict_outcome(feature_matrix, weights)\n",
    "    ro_i = (feature_matrix[:, i] * (output - predictions + (weights[i]*feature_matrix[:,i]))).sum()\n",
    "    if i == 0: \n",
    "        new_weight_i = ro_i\n",
    "    elif ro_i < - l1_penalty/2.:\n",
    "        new_weight_i = ro_i + l1_penalty/2.\n",
    "    elif ro_i > l1_penalty/2.: \n",
    "        new_weight_i =ro_i - l1_penalty/2.\n",
    "    else: \n",
    "        new_weight_i = 0. \n",
    "\n",
    "    return (new_weight_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4255588466910251\n"
     ]
    }
   ],
   "source": [
    "print(lasso_coordinate_descent_step(1, np.array([[3./sqrt(13),1./sqrt(10)],\n",
    "                   [2./sqrt(13),3./sqrt(10)]]), np.array([1., 1.]), np.array([1., 4.]), 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking whether or not, ro[j] falls within the boundaries of a specific l1_penalty, if it does, then that value is knocked out or reduced to 0 (this just means that the correlation value on this jth feature is insignificant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_l1range(value, penalty):\n",
    "    return((value>=-penalty/2.) and (value<= penalty/2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 140000000.0 penalty: \n",
      " 1. Would the model knock out sqft_living? Ans: False \n",
      " 2. Would the model knock out bedrooms? Ans: False\n",
      "for 164000000.0 penalty: \n",
      " 1. Would the model knock out sqft_living? Ans: False \n",
      " 2. Would the model knock out bedrooms? Ans: True\n",
      "for 173000000.0 penalty: \n",
      " 1. Would the model knock out sqft_living? Ans: False \n",
      " 2. Would the model knock out bedrooms? Ans: True\n",
      "for 190000000.0 penalty: \n",
      " 1. Would the model knock out sqft_living? Ans: True \n",
      " 2. Would the model knock out bedrooms? Ans: True\n",
      "for 230000000.0 penalty: \n",
      " 1. Would the model knock out sqft_living? Ans: True \n",
      " 2. Would the model knock out bedrooms? Ans: True\n"
     ]
    }
   ],
   "source": [
    "for l1_penalty in [1.4e8, 1.64e8, 1.73e8, 1.9e8, 2.3e8]:\n",
    "    print('for {} penalty: \\n 1. Would the model knock out sqft_living? Ans: {} \\n 2. Would the model knock out bedrooms? Ans: {}' .format(l1_penalty, in_l1range(ro[1], l1_penalty), in_l1range(ro[2], l1_penalty)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_cyclical_coordinate_descent(feature_matrix, output, initial_weights, l1_penalty, tolerance):\n",
    "    weights = np.array(initial_weights)\n",
    "    delta = np.array(initial_weights) * 0.0 \n",
    "    converged = False \n",
    "    while not converged: \n",
    "        for index in range(feature_matrix.shape[1]):\n",
    "            #print('For Feature:', index)\n",
    "            new_weight = lasso_coordinate_descent_step(index, feature_matrix, output, weights, l1_penalty)\n",
    "            delta[index] = np.abs(new_weight - weights[index])\n",
    "            #print('old weight:', weights[index])\n",
    "            #print('new_weight:', new_weight)\n",
    "            #print('change in weights', delta[index])\n",
    "            #print('              ')\n",
    "            weights[index] = new_weight\n",
    "        max_change = max(delta)\n",
    "        #print('max change is:', max_change)\n",
    "        #print('               ')\n",
    "        \n",
    "        if max_change < tolerance:\n",
    "            converged = True\n",
    "    return weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = np.zeros(3)\n",
    "l1_penalty = 1e7\n",
    "tolerance = 1.0\n",
    "#features_matrix\n",
    "#normalized_features\n",
    "#norm\n",
    "\n",
    "weights = lasso_cyclical_coordinate_descent(normalized_features, output, initial_weights, l1_penalty, tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21624997.95951909, 63157247.20788956,        0.        ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1630492476715386.5\n"
     ]
    }
   ],
   "source": [
    "prediction = predict_outcome(normalized_features, weights)\n",
    "residuals = output - prediction\n",
    "RSS = np.dot(residuals, residuals)\n",
    "print(RSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = ['bedrooms',\n",
    "                'bathrooms',\n",
    "                'sqft_living',\n",
    "                'sqft_lot',\n",
    "                'floors',\n",
    "                'waterfront', \n",
    "                'view', \n",
    "                'condition', \n",
    "                'grade',\n",
    "                'sqft_above',\n",
    "                'sqft_basement',\n",
    "                'yr_built', \n",
    "                'yr_renovated']\n",
    "\n",
    "target = 'price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "(multi_features_matrix, multi_output) = get_features_matrix(train_sales, all_features, target)\n",
    "(normalized_multi_features, multi_norm) = norms(multi_features_matrix)\n",
    "\n",
    "multi_initial_weights = np.zeros(len(all_features) + 1)\n",
    "multi_l1_penalty1 = 1e7 \n",
    "multi_tolerance = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24429600.23440312,        0.        ,        0.        ,\n",
       "       48389174.77154896,        0.        ,        0.        ,\n",
       "        3317511.21492165,  7329961.81171425,        0.        ,\n",
       "              0.        ,        0.        ,        0.        ,\n",
       "              0.        ,        0.        ])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights1e7 = lasso_cyclical_coordinate_descent(normalized_multi_features, multi_output, multi_initial_weights, multi_l1_penalty1, multi_tolerance)\n",
    "weights1e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([71114625.71488702,        0.        ,        0.        ,\n",
       "              0.        ,        0.        ,        0.        ,\n",
       "              0.        ,        0.        ,        0.        ,\n",
       "              0.        ,        0.        ,        0.        ,\n",
       "              0.        ,        0.        ])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_l1_penalty2 = 1e8\n",
    "multi_tolerance = 1.0\n",
    "\n",
    "weights1e8 = lasso_cyclical_coordinate_descent(normalized_multi_features, multi_output, multi_initial_weights, multi_l1_penalty2, multi_tolerance)\n",
    "weights1e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 78564738.34156762, -22097398.92430532,  12791071.87278517,\n",
       "        93808088.09281193,  -2013172.75704954,  -4219184.93265014,\n",
       "         6482842.81753506,   7127408.53480689,   5001664.8546964 ,\n",
       "        14327518.43714051, -15770959.15237397,  -5159591.22213147,\n",
       "       -84495341.7684364 ,   2824439.49703683])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_l1_penalty3 = 1e4\n",
    "multi_tolerance2 = 5e5\n",
    "\n",
    "weights1e4 = lasso_cyclical_coordinate_descent(normalized_multi_features, multi_output, multi_initial_weights, multi_l1_penalty3, multi_tolerance2)\n",
    "weights1e4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test these weights on the TEST data set we need to find the normalized features for the test data as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_features_matrix, test_output) = get_features_matrix(test_sales, all_features, target)\n",
    "(normalized_test_features, test_norm) = norms(test_features_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1568106721719153.2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_1e7 = predict_outcome(normalized_test_features, weights1e7)\n",
    "residuals_1e7 = test_output - prediction_1e7\n",
    "RSS1e7 = (residuals_1e7**2).sum()\n",
    "RSS1e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1818706228108472.2"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_1e8 = predict_outcome(normalized_test_features, weights1e8)\n",
    "residuals_1e8 = test_output - prediction_1e8\n",
    "RSS1e8 = (residuals_1e8**2).sum()\n",
    "RSS1e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1855844223399372.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_1e4 = predict_outcome(normalized_test_features, weights1e4)\n",
    "residuals_1e4 = test_output - prediction_1e4\n",
    "RSS1e4 = (residuals_1e4**2).sum()\n",
    "RSS1e4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instead of normalizing the test features, we can try normalizing the weights themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1e7_normalized = weights1e7 / multi_norm\n",
    "weights1e8_normalized = weights1e8 / multi_norm\n",
    "weights1e4_normalized = weights1e4 / multi_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275962075920366.78"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_1e7_2 = predict_outcome(test_features_matrix, weights1e7_normalized)\n",
    "residuals_1e7_2 = test_output - prediction_1e7_2\n",
    "RSS_1e7_2 = (residuals_1e7_2**2).sum()\n",
    "RSS_1e7_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537166151497322.75"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_1e8_2 = predict_outcome(test_features_matrix, weights1e8_normalized)\n",
    "residuals_1e8_2 = test_output - prediction_1e8_2\n",
    "RSS_1e8_2 = (residuals_1e8_2**2).sum()\n",
    "RSS_1e8_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228459958971393.25"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_1e4_2 = predict_outcome(test_features_matrix, weights1e4_normalized)\n",
    "residuals_1e4_2 = test_output - prediction_1e4_2\n",
    "RSS_1e4_2 = (residuals_1e4_2**2).sum()\n",
    "RSS_1e4_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
